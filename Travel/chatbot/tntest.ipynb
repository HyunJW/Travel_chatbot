{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from Preprocess import Preprocess\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input, Bidirectional, TimeDistributed, Embedding, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   nouns label\n",
      "0  반갑습니다     O\n",
      "1     소속     O\n",
      "2     상담     O\n",
      "3      사     O\n",
      "4     이름     O\n"
     ]
    }
   ],
   "source": [
    "# 학습용 데이터 로드\n",
    "ner = pd.read_csv('../data/수정데이터/명사들.csv', index_col=0)\n",
    "ner.dropna(inplace=True)\n",
    "print(ner.head())\n",
    "p = Preprocess(word2index_dic='../data/chatbot_dict.bin',\n",
    "               userdic=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nouns    False\n",
       "label    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nouns</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [nouns, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner[ner['nouns'].str.len() == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label  count\n",
      "0   B_A    116\n",
      "1   B_C     66\n",
      "2  B_DT     47\n",
      "3   B_P     31\n",
      "4   B_R    351\n",
      "5   B_T     60\n",
      "6     I     31\n",
      "7     O  59576\n",
      "8     X      6\n"
     ]
    }
   ],
   "source": [
    "# BIO태그별 각각의 값의 개수 카운트'\n",
    "print(ner.groupby('label').size().reset_index(name='count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nouns 열의 중복을 제거한 값의 개수 : 60282\n",
      "60284\n"
     ]
    }
   ],
   "source": [
    "# Word 열의 중복을 제거한 값의 개수\n",
    "print('nouns 열의 중복을 제거한 값의 개수 : {}'.format(ner['nouns'].nunique()))\n",
    "print(ner.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 개수: 60284\n",
      "0번 째 샘플 단어 시퀀스: 반갑습니다\n",
      "0번 째 샘플 bio 태그: O\n",
      "샘플 단어 시퀀스 최대 길이: 50\n",
      "샘플 단어 시퀀스 평균 길이: 3.8354289695441577\n"
     ]
    }
   ],
   "source": [
    "# 말뭉치 데이터에서 단어와 BIO태그만 불러와 학습용 데이터셋 생성\n",
    "words, tags = ner['nouns'], ner['label']\n",
    "\n",
    "print('샘플 개수:', len(words))\n",
    "print('0번 째 샘플 단어 시퀀스:', words[0])\n",
    "print('0번 째 샘플 bio 태그:', tags[0])\n",
    "print('샘플 단어 시퀀스 최대 길이:', max(len(l) for l in words))\n",
    "print('샘플 단어 시퀀스 평균 길이:', (sum(map(len, words)) / len(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이저 정의\n",
    "tag_tokenizer = preprocessing.text.Tokenizer(lower=False)\n",
    "tag_tokenizer.fit_on_texts(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIO 태그 사전 크기: 11\n",
      "단어 사전 크기: 91132\n"
     ]
    }
   ],
   "source": [
    "# 단어사전 및 태그 사전 크기\n",
    "vocab_size = len(p.word_index) + 1\n",
    "tag_size = len(tag_tokenizer.word_index) + 1\n",
    "print('BIO 태그 사전 크기:', tag_size)\n",
    "print('단어 사전 크기:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용 단어 시퀀스 생성\n",
    "x_train = [p.get_wordidx_sequence(word) for word in words]\n",
    "y_train = tag_tokenizer.texts_to_sequences(tags)\n",
    "index_to_ner = tag_tokenizer.index_word # 시퀀스 인덱스를 NER로 변환 하기 위해 사용\n",
    "index_to_ner[0] = 'PAD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시퀀스 패딩 처리\n",
    "max_len = 50\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train, padding='post', maxlen=max_len)\n",
    "y_train = preprocessing.sequence.pad_sequences(y_train, padding='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터와 테스트 데이터 분리\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 샘플 시퀀스 형상: (48227, 50)\n",
      "학습 샘플 레이블 형상: (48227, 50, 11)\n",
      "테스트 샘플 시퀀스 형상: (12057, 50)\n",
      "테스트 샘플 레이블 형상: (12057, 50, 11)\n"
     ]
    }
   ],
   "source": [
    "# 출력 데이터 원핫인코딩\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=tag_size)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=tag_size)\n",
    "\n",
    "print('학습 샘플 시퀀스 형상:', x_train.shape)\n",
    "print('학습 샘플 레이블 형상:', y_train.shape)\n",
    "print('테스트 샘플 시퀀스 형상:', x_test.shape)\n",
    "print('테스트 샘플 레이블 형상:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/10\n",
      "377/377 [==============================] - 305s 782ms/step - loss: 0.0748 - accuracy: 0.7904\n",
      "Epoch 2/10\n",
      "377/377 [==============================] - 327s 868ms/step - loss: 0.0108 - accuracy: 0.9728\n",
      "Epoch 3/10\n",
      "377/377 [==============================] - 314s 834ms/step - loss: 0.0054 - accuracy: 0.9883\n",
      "Epoch 4/10\n",
      "377/377 [==============================] - 308s 816ms/step - loss: 0.0042 - accuracy: 0.9898\n",
      "Epoch 5/10\n",
      "377/377 [==============================] - 308s 817ms/step - loss: 0.0037 - accuracy: 0.9905\n",
      "Epoch 6/10\n",
      "377/377 [==============================] - 316s 837ms/step - loss: 0.0035 - accuracy: 0.9911\n",
      "Epoch 7/10\n",
      "377/377 [==============================] - 315s 835ms/step - loss: 0.0033 - accuracy: 0.9921\n",
      "Epoch 8/10\n",
      "377/377 [==============================] - 313s 829ms/step - loss: 0.0031 - accuracy: 0.9931\n",
      "Epoch 9/10\n",
      "377/377 [==============================] - 309s 818ms/step - loss: 0.0030 - accuracy: 0.9938\n",
      "Epoch 10/10\n",
      "377/377 [==============================] - 304s 805ms/step - loss: 0.0029 - accuracy: 0.9941\n"
     ]
    }
   ],
   "source": [
    "# 모델 정의 (Bi-LSTM)\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len, mask_zero=True))\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True, dropout=0.50, recurrent_dropout=0.25)))\n",
    "model.add(TimeDistributed(Dense(tag_size, activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.0001), metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=10)\n",
    "model.save('./model/ner_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "377/377 [==============================] - 41s 107ms/step - loss: 0.0033 - accuracy: 0.9930\n",
      "평가 결과: 0.9929937124252319\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "from tensorflow import keras\n",
    "model = keras.models.load_model('./model/ner_model.h5')\n",
    "print('평가 결과:', model.evaluate(x_test, y_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시퀀스를 NER 태그로 변환하는 함수\n",
    "def sequences_to_tag(sequences):\n",
    "    result = []\n",
    "    for sequence in sequences:\n",
    "        temp = []\n",
    "        for pred in sequence:\n",
    "            pred_index = np.argmax(pred)\n",
    "            temp.append(index_to_ner[pred_index].replace('PAD', 'O'))\n",
    "        result.append(temp)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377/377 [==============================] - 41s 109ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: R seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: T seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: A seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: DT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: P seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           T       0.00      0.00      0.00         9\n",
      "           _       0.00      0.00      0.00        14\n",
      "\n",
      "   micro avg       0.00      0.00      0.00        23\n",
      "   macro avg       0.00      0.00      0.00        23\n",
      "weighted avg       0.00      0.00      0.00        23\n",
      "\n",
      "F1-score: 0.0%\n"
     ]
    }
   ],
   "source": [
    "# f1 스코어\n",
    "from seqeval.metrics import f1_score, classification_report\n",
    "y_predicted = model.predict([x_test]) # 테스트 데이터셋의 NER 예측\n",
    "pred_tags = sequences_to_tag(y_predicted) # 예측된 NER\n",
    "test_tags = sequences_to_tag(y_test) # 실제 NER\n",
    "print(classification_report(test_tags, pred_tags))\n",
    "print('F1-score: {:.1%}'.format(f1_score(test_tags, pred_tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 정의\n",
    "# from keras_crf import CRFModel\n",
    "\n",
    "# embedding_dim = 128\n",
    "# hidden_units = 64\n",
    "# dropout_ratio = 0.3\n",
    "# adam = Adam(learning_rate=0.001)\n",
    "\n",
    "# sequence_input = Input(shape=(max_len, ), dtype=tf.int32, name='sequence_input')\n",
    "# model_embedding = Embedding(input_dim=vocab_size,\n",
    "#                             output_dim=embedding_dim,\n",
    "#                             input_length=max_len)(sequence_input)\n",
    "# model_bilstm = Bidirectional(LSTM(hidden_units, return_sequences=True))\n",
    "# model_dropout = TimeDistributed(Dropout(dropout_ratio))(model_bilstm)\n",
    "# model_dense = TimeDistributed(Dense(tag_size, activation='relu'))(model_dropout)\n",
    "# base = Model(inputs=sequence_input, outputs=model_dense)\n",
    "# model = CRFModel(base, tag_size)\n",
    "# model.compile(optimizer=adam, metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "# mc = ModelCheckpoint('bilstm_crf/cp.ckpt', monitor='val_decode_sequence_accuracy', mode='max', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "# history = model.fit(x_train, y_train.astype(int), batch_size=128, epochs=10, callbacks=[mc, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
